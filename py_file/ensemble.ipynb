{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD as SVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sythetic_ver2 import Sythetic\n",
    "from sythetic_ver2 import txn_class\n",
    "from sythetic_ver2 import cust_class\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.ensemble.bagging import _generate_indices\n",
    "from sklearn.ensemble.bagging import _generate_bagging_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x14237 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 112837 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=txn_class(5,[[.9,.1,.0,.0,.0,.0,.0,.0,.0,.0], #single-pattern\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1]])\n",
    "\n",
    "t2=txn_class(5,[[.1,.9,.0,.0,.0,.0,.0,.0,.0,.0], #two-order interactive-items\n",
    "               [.9,.1,.0,.0,.0,.0,.0,.0,.0,.0],\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1]])\n",
    "\n",
    "t3=txn_class(5,[[.1,.1,.1,.1,.1,.1,.1,.1,.1,.1], #two-order interactive-items\n",
    "               [.1,.0,.0,.0,.1,.0,.1,.0,.7,.0],\n",
    "               [.1,.0,.0,.0,.1,.1,.1,.6,.0,.0],\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "               [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1]])\n",
    "\n",
    "t4=txn_class(5,[[.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],#three-order interactive-items\n",
    "                [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "                [.0,.0,.0,.0,.1,.8,.1,.0,.0,.0],\n",
    "                [.0,.0,.0,.0,.0,.1,.8,.1,.0,.0],\n",
    "                [.0,.0,.0,.0,.0,.0,.1,.8,.1,.0]])\n",
    "\n",
    "t5=txn_class(5,[[.0,.0,.9,.0,.0,.0,.0,.0,.0,.1],#full-order interactive-items\n",
    "                [.1,.0,.9,.0,.0,.0,.0,.0,.0,.0],\n",
    "                [.0,.0,.9,.0,.0,.1,.0,.0,.0,.0],\n",
    "                [.0,.0,.0,.0,.9,.0,.0,.1,.0,.0],\n",
    "                [.0,.0,.0,.0,.9,.0,.1,.0,.0,.0]])\n",
    "\n",
    "t6=txn_class(5,[[.0,.0,.8,.0,.0,.1,.0,.0,.0,.1],#full-order interactive-items\n",
    "                [.1,.0,.9,.0,.0,.0,.0,.0,.0,.0],\n",
    "                [.0,.0,.7,.1,.0,.1,.1,.0,.0,.0],\n",
    "                [.1,.0,.1,.0,.7,.0,.0,.1,.0,.0],\n",
    "                [.1,.0,.1,.0,.1,.0,.1,.0,.6,.0]])\n",
    "\n",
    "t7=txn_class(5,[[.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],#random sample\n",
    "                [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "                [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "                [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1],\n",
    "                [.1,.1,.1,.1,.1,.1,.1,.1,.1,.1]])\n",
    "\n",
    "c1=cust_class(0,t1,t2,t7)\n",
    "c2=cust_class(1,t3,t4,t7)\n",
    "c3=cust_class(2,t5,t6,t7)\n",
    "\n",
    "s=Sythetic()\n",
    "s.doc_final([(c1,[50,50,50],50),(c2,[50,50,50],50),(c3,[50,50,50],50)],'full')\n",
    "s.count2vect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampleing(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 random_state=None, \n",
    "                 bootstrap_features=False,\n",
    "                 bootstrap_samples=False, \n",
    "                 n_features=10, \n",
    "                 n_samples=10,\n",
    "                 max_features=5, \n",
    "                 max_samples=5):\n",
    "        self.random_state=random_state\n",
    "        self.bootstrap_features=bootstrap_features\n",
    "        self.bootstrap_samples=bootstrap_samples\n",
    "        self.n_features=n_features\n",
    "        self.n_samples=n_samples\n",
    "        self.max_features=max_features\n",
    "        self.max_samples=max_samples\n",
    "    \n",
    "    def fit(self,X):\n",
    "        if issparse(X):\n",
    "            self.X=X.toarray()\n",
    "        else:\n",
    "            self.X=X\n",
    "        self.n_samples=len(self.X)\n",
    "        self.n_features=self.X.shape[1]\n",
    "        if self.max_samples<=1:\n",
    "            self.max_samples=int(self.n_samples*self.max_samples)\n",
    "        if self.max_features<=1:\n",
    "            self.max_features=int(self.n_features*self.max_features)\n",
    "        self.feat_indices,self.sample_indices=_generate_bagging_indices(self.random_state, \n",
    "                                                              self.bootstrap_features,\n",
    "                                                              self.bootstrap_samples, \n",
    "                                                              self.n_features, \n",
    "                                                              self.n_samples,\n",
    "                                                              self.max_features, \n",
    "                                                              self.max_samples)\n",
    "        \n",
    "        return self.feat_indices,self.sample_indices\n",
    "    \n",
    "    def fit_transform(self,X):\n",
    "        feat_indices,sample_indices=self.fit(X)\n",
    "        return (self.X[sample_indices])[:,feat_indices]\n",
    "    \n",
    "    def transform(self,new_X):# new_X is a 2D-matrix\n",
    "        return new_X[:,self.feat_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pasting(Sampleing): # Pasting is sampleing samples without replacement\n",
    "    def __init__(self,\n",
    "                 random_state=None, \n",
    "                 bootstrap_features=False,\n",
    "                 bootstrap_samples=False, \n",
    "                 max_features=1,\n",
    "                 max_samples=0.8 \n",
    "                ):\n",
    "\n",
    "        super().__init__(\n",
    "                 random_state=random_state, \n",
    "                 bootstrap_features=bootstrap_features,\n",
    "                 bootstrap_samples=bootstrap_samples, \n",
    "                 max_features=max_features,\n",
    "                 max_samples=max_samples \n",
    "                 )\n",
    "        \n",
    "class Bagging(Sampleing): # Bagging is sampleing samples with replacement(bootstrap)\n",
    "    def __init__(self,\n",
    "                 random_state=None, \n",
    "                 bootstrap_features=False,\n",
    "                 bootstrap_samples=True, \n",
    "                 max_features=1,\n",
    "                 max_samples=0.8 \n",
    "                ):\n",
    "\n",
    "        super().__init__(\n",
    "                 random_state=random_state, \n",
    "                 bootstrap_features=bootstrap_features,\n",
    "                 bootstrap_samples=bootstrap_samples, \n",
    "                 max_features=max_features,\n",
    "                 max_samples=max_samples \n",
    "                 )\n",
    "        \n",
    "class Random_Subspaces(Sampleing): # Random_Subspaces is sampleing features with replacement\n",
    "    def __init__(self,\n",
    "                 random_state=None, \n",
    "                 bootstrap_features=True,\n",
    "                 bootstrap_samples=False, \n",
    "                 max_features=0.8,\n",
    "                 max_samples=1\n",
    "                ):\n",
    "\n",
    "        super().__init__(\n",
    "                 random_state=random_state, \n",
    "                 bootstrap_features=bootstrap_features,\n",
    "                 bootstrap_samples=bootstrap_samples, \n",
    "                 max_features=max_features,\n",
    "                 max_samples=max_samples \n",
    "                 )\n",
    "        \n",
    "class Random_Patches(Sampleing): # Random_Patches is sampleing both on samples and features with replacement\n",
    "    def __init__(self,\n",
    "                 random_state=None, \n",
    "                 bootstrap_features=True,\n",
    "                 bootstrap_samples=True, \n",
    "                 max_features=0.8,\n",
    "                 max_samples=0.8\n",
    "                ):\n",
    "\n",
    "        super().__init__(\n",
    "                 random_state=random_state, \n",
    "                 bootstrap_features=bootstrap_features,\n",
    "                 bootstrap_samples=bootstrap_samples, \n",
    "                 max_features=max_features,\n",
    "                 max_samples=max_samples \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dic={'sampling':[Pasting,Bagging,Random_Subspaces,Random_Patches],'dim_dedu':[SVD,PCA],'cluster':[KMeans]}\n",
    "# add more alternatives in 'dim_deduction' and 'cluster'\n",
    "class estimator():\n",
    "    \n",
    "    def __init__(self,model_dic):\n",
    "        self.layer0=choice(model_dic['sampling'],1)[0]\n",
    "        self.layer1=choice(model_dic['dim_dedu'],1)[0]\n",
    "        self.layer2=choice(model_dic['cluster'],1)[0]\n",
    "        \n",
    "        \n",
    "    def fit(self,X,K):\n",
    "        self.layer0_=self.layer0(max_samples=0.9)\n",
    "        self.layer0_output=self.layer0_.fit_transform(X)\n",
    "        self.layer1_=self.layer1(n_components=K)\n",
    "        self.layer1_output=self.layer1_.fit_transform(self.layer0_output)\n",
    "        self.layer2_=self.layer2(n_clusters=K)\n",
    "        self.layer2_.fit(self.layer1_output)\n",
    "        #print('fit successfully!')\n",
    "    \n",
    "    def pairwise_predict(self,c1,c2):\n",
    "        c1_layer0_output=self.layer0_.transform(c1)\n",
    "        c1_layer1_output=self.layer1_.transform(c1_layer0_output)\n",
    "        c1_label=self.layer2_.predict(c1_layer1_output)\n",
    "        #print(c1_label)\n",
    "        c2_layer0_output=self.layer0_.transform(c2)\n",
    "        c2_layer1_output=self.layer1_.transform(c2_layer0_output)\n",
    "        c2_label=self.layer2_.predict(c2_layer1_output)\n",
    "        #print(c2_label)\n",
    "        return (c1_label[0]!=c2_label[0])# if not same class return True\n",
    "\n",
    "class ensemble():\n",
    "\n",
    "    def __init__(self,n_estimators,model_dic):\n",
    "        self.n_setimators=n_estimators\n",
    "        self.estimators_=[estimator(model_dic) for i in range(self.n_setimators)]\n",
    "    \n",
    "    def fit(self,X,K):\n",
    "        self.training_X=X\n",
    "        for est in self.estimators_:\n",
    "            est.fit(X,K)\n",
    "    \n",
    "    def pairwise_predict(self,c1,c2):\n",
    "        self.est_pred=[]\n",
    "        for est in self.estimators_:\n",
    "            self.est_pred.append(est.pairwise_predict(c1,c2))\n",
    "        prob_diff_class=(sum(self.est_pred)+0.0)/len(self.est_pred)\n",
    "        return prob_diff_class\n",
    "    \n",
    "    def cust_diff_mat(self,X_new):\n",
    "        new_cust_num=len(X_new)\n",
    "        cust_diff_mat=np.zeros((new_cust_num,new_cust_num))\n",
    "        for idx_cust in range(new_cust_num-1):\n",
    "            for idx_latter in range(idx_cust+1,new_cust_num):\n",
    "                c1=np.array([X_new[idx_cust]])\n",
    "                c2=np.array([X_new[idx_latter]])\n",
    "                cust_diff_mat[idx_cust,idx_latter]=self.pairwise_predict(c1,c2)\n",
    "        cust_diff_mat+=cust_diff_mat.T\n",
    "        return cust_diff_mat\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=ensemble(5,model_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.fit(X=s.count_mat,K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cust=s.count_mat.toarray()[45:55]# from 45-50 customers are class1, 50-55 customers are class2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.cust_diff_mat(new_cust)\n",
    "# this is customers mutual difference matrix, \n",
    "# the cell with rows_i, col_j represents the prob of customer_i, customer_j are in different class.\n",
    "# 0. means they are almost the same class, 1. means they are very different that should be different class.\n",
    "# this value is up to the voting result from ensemble methods, whose voting values are generated by all estimators in ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.Pasting,\n",
       " __main__.Pasting,\n",
       " __main__.Bagging,\n",
       " __main__.Random_Patches,\n",
       " __main__.Random_Patches]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.estimators_[i].layer0 for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sklearn.decomposition.pca.PCA,\n",
       " sklearn.decomposition.truncated_svd.TruncatedSVD,\n",
       " sklearn.decomposition.pca.PCA,\n",
       " sklearn.decomposition.pca.PCA,\n",
       " sklearn.decomposition.pca.PCA]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.estimators_[i].layer1 for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sklearn.cluster.k_means_.KMeans,\n",
       " sklearn.cluster.k_means_.KMeans,\n",
       " sklearn.cluster.k_means_.KMeans,\n",
       " sklearn.cluster.k_means_.KMeans,\n",
       " sklearn.cluster.k_means_.KMeans]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.estimators_[i].layer2 for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
