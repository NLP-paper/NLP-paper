{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I design an end-to-end ensemble method below. It can automatically process data without any human involvement at all. As long as you provide the orignal data frame and the position information about categorical and interval features, it can automatically run and return the prediction directly.\n",
    "### It is actually a customizing pipeline with three phases from feature encoding, dimension deduction to final classifiers(regressors). Also you can plug in more phases into the pipeline if you want. The advantage of this method than Sklearn pipeline(also my innovation) is I create a new ordinal encoder class so that training set and testing set can be processed independently at the very begining!\n",
    "### There are some annoying issuses of Sklearn Encoding class: 1. Label encoder can only be applied on a single feature and at the trsanform stage, any new value without encoding at fit stage is not allowed, whic means you have to perform label encoder on the entire dataset. Once new samples come in, it will fail to transform. 2. Ordinal encoder is a bit better than label encoder for handling multiple features simultaneously. However, since it do not have the input parameter handl_unknown like Onehot encoder, it is still not able to process new values in features at the transform stage. Onehot encdoer is the most powerful encoder since it is able to handle unknown values and can handle features simultaneously. BUT the most frustrating point is Onehot encoder can be used only on the features with integer or float data type. So you have to use the former two encoder to convert string features to numeric features! This will greatly increase the difficulty of your automation and pipeline.\n",
    "### My new OrdinalEncoder solves the above isses and make the entire automation come true! Some codes in this notebook are referenced the paper Customer Segmentation based  on Financial Behavior. I am one of the coauthor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.pickle','rb') as load:\n",
    "    data=pickle.load(load)\n",
    "with open('y.pickle','rb') as load:\n",
    "    y=pickle.load(load)\n",
    "with open('train_test_index.pickle','rb') as load:\n",
    "    train_test_index=pickle.load(load)\n",
    "with open('feature_final.pickle','rb') as load:\n",
    "    feature_final=pickle.load(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Customizing Ensemble Method \n",
    "## Reference Paper Customer Segemntation based on Financial Behavior, Author: Kecheng Xu, etc.\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "from numpy.random import choice\n",
    "from sklearn.decomposition import TruncatedSVD as SVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tqdm import tqdm_notebook as tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three class we have: OrdinalEncoder, estimator, ensemble.\n",
    "## You only need to generate the instance of ensemble, input the estimetor amount, dataframe and categorcial features position value into ensemble instance. Then it will directly return the prediction.\n",
    "## An instance of estimator contains three phases: encoding, dimension deduction and ensemble classifiers.  \n",
    "## An instance of ensemble is consisted of many independent estimators, it will calculate the mean value of each prediction(probability) generated by a single estimator. \n",
    "## You can add more alternatives in each stage(layer) of estimator without any adjustment as long as the estimator align the fit, fit_transorm and transform pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalEncoder():\n",
    "    def __init__(self):\n",
    "        self.dicts=[]\n",
    "        \n",
    "    def fit(self,df,line):\n",
    "        self.line=line\n",
    "        df_output=df.copy()\n",
    "        for i in range(line):\n",
    "            dic=np.unique(df.iloc[:,i])\n",
    "            dic=dict([(i,index) for index, i in enumerate(dic)])\n",
    "            self.dicts.append(dic)\n",
    "            \n",
    "    def fit_transform(self,df,line):\n",
    "        self.line=line\n",
    "        df_output=df.copy()\n",
    "        for i in range(line):\n",
    "            dic=np.unique(df.iloc[:,i])\n",
    "            dic=dict([(i,index) for index, i in enumerate(dic)])\n",
    "            self.dicts.append(dic)\n",
    "            df_output.iloc[:,i]=df.iloc[:,i].apply(lambda x: dic[x])\n",
    "        return df_output\n",
    "        \n",
    "    def transform(self,df):\n",
    "        df_output=df.copy()\n",
    "        for i in range(self.line):\n",
    "            dic=self.dicts[i]\n",
    "            df_output.iloc[:,i]=df.iloc[:,i].apply(self.unknown_value,args=(dic,))\n",
    "        return df_output\n",
    "    \n",
    "    def unknown_value(self,value,dic): # It will set up a new interger for unknown values!\n",
    "        try:\n",
    "            return dic[i]\n",
    "        except:\n",
    "            return len(dic)\n",
    "                \n",
    "class estimator():\n",
    "    \n",
    "    def __init__(self,model_dic):# Choose an alternative in each layer!\n",
    "        self.layer0=choice(model_dic['Encoding'],1)[0]\n",
    "        self.layer1=choice(model_dic['Dimdeduct'],1)[0]\n",
    "        self.layer2=choice(model_dic['Classifer'],1)[0]\n",
    "        \n",
    "        \n",
    "    def fit(self,X,y,K,ord_output,ohe_output):#Three layer fitting process\n",
    "    \n",
    "        if self.layer0.__name__=='OrdinalEncoder':\n",
    "            layer0_output=ord_output\n",
    "        else:\n",
    "            layer0_output=ohe_output\n",
    "        self.layer1_=self.layer1(n_components=K)\n",
    "        layer1_output=self.layer1_.fit_transform(layer0_output)\n",
    "        self.layer2_=self.layer2()\n",
    "        self.layer2_.fit(layer1_output,y)\n",
    "    \n",
    "        \n",
    "    def predict(self,ord_output,ohe_output):#Three layer fitting process\n",
    "        if self.layer0.__name__=='OrdinalEncoder':\n",
    "            layer0_output=ord_output\n",
    "        else:\n",
    "            layer0_output=ohe_output\n",
    "        layer1_output=self.layer1_.transform(layer0_output)\n",
    "        return self.layer2_.predict_proba(layer1_output)\n",
    "        \n",
    "class ensemble():\n",
    "\n",
    "    def __init__(self,n_estimators,model_dic):\n",
    "        self.n_setimators=n_estimators\n",
    "        self.estimators_=[estimator(model_dic) for i in range(self.n_setimators)]\n",
    "        self.cate_int_line=model_dic['categorical_interval_line']\n",
    "        self.est_complete=0\n",
    "    \n",
    "    def fit(self,X,y,K):\n",
    "        self.OrdinalEncoder_=OrdinalEncoder()\n",
    "        OrdinalEncoder_output=self.OrdinalEncoder_.fit_transform(X,self.cate_int_line)\n",
    "        self.OnehotEncoder_=OneHotEncoder(categorical_features=list(range(self.cate_int_line)),handle_unknown='ignore')\n",
    "        OnehotEncoder_output=self.OnehotEncoder_.fit_transform(OrdinalEncoder_output)\n",
    "        \n",
    "        for est in tqdm(self.estimators_):\n",
    "            est.fit(X,y,K,OrdinalEncoder_output,OnehotEncoder_output)\n",
    "            self.est_complete+=1\n",
    "            print('Complete '+str(self.est_complete)+' estimator!')\n",
    "    \n",
    "    def predict(self,X):\n",
    "        prob=[]\n",
    "        ord_output=self.OrdinalEncoder_.transform(X)\n",
    "        ohe_output=self.OnehotEncoder_.transform(ord_output)\n",
    "        for est in tqdm(self.estimators_):\n",
    "            prob.append(est.predict(ord_output,ohe_output))\n",
    "        prob=np.array(prob)\n",
    "        return np.mean(prob,axis=0)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and predicting process only need below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3aeaa0d59f4499b35eca6c3f86fc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete 1 estimator!\n",
      "Complete 2 estimator!\n",
      "Complete 3 estimator!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dic={'Encoding':[OrdinalEncoder,OneHotEncoder],\n",
    "            'Dimdeduct':[SVD,NMF],\n",
    "            'Classifer':[RandomForestClassifier,\n",
    "                         XGBClassifier,\n",
    "                         AdaBoostClassifier,\n",
    "                         GradientBoostingClassifier],\n",
    "            'categorical_interval_line':22 }\n",
    "\n",
    "x_train=data.iloc[train_test_index['x_train'],:]\n",
    "y_train=y[train_test_index['y_train']]\n",
    "e=ensemble(3,model_dic)\n",
    "e.fit(x_train,y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931f925ed4a34beca490a5e9c570573c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9276315 , 0.0723685 ],\n",
       "       [0.91814008, 0.08185992],\n",
       "       [0.96044548, 0.03955452],\n",
       "       ...,\n",
       "       [0.85566963, 0.14433037],\n",
       "       [0.85260338, 0.14739662],\n",
       "       [0.95337461, 0.04662539]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=data.iloc[train_test_index['x_test'],:]\n",
    "y_train=y[train_test_index['y_test']]\n",
    "y_predict=e.predict(x_test)\n",
    "y_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
